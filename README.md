# AI Inference Platform with OCR + LLM Integration

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-%230db7ed.svg?style=flat&logo=docker&logoColor=white)](https://www.docker.com/)

A production-ready AI inference platform that combines Optical Character Recognition (OCR) with Large Language Models (LLM) for intelligent document processing and analysis.

## ğŸš€ Features

### Core Capabilities
- **Multi-Provider OCR**: Support for Tesseract, TrOCR (Hugging Face), and configurable OCR engines
- **Document Text Extraction**: LangChain-powered extraction from PDF, Word, Excel, PowerPoint, and more
- **LLM Integration**: Seamless integration with Ollama, OpenAI, and other LLM providers
- **Flow-Based Architecture**: Configurable processing pipelines using YAML DSL
- **Document Analysis**: Intelligent extraction of entities, summaries, and structured data
- **Multi-Language Support**: 40+ languages supported for OCR processing

### Document Analysis Flow (NEW!)
- **Complete Workflow**: End-to-end document processing with extraction + LLM analysis
- **Multi-Format Support**: PDF, Word (.docx/.doc), Excel (.xlsx/.xls), PowerPoint (.pptx/.ppt)
- **Text Files**: Plain text, CSV, Markdown, RTF support
- **Smart Chunking**: Automatic text splitting for optimal LLM processing
- **LangChain Integration**: Leverages proven document loaders
- **Flow-Based Architecture**: Follows established patterns with proper step tracking

### OCR Providers
- **Tesseract**: Excellent for documents and scene text (recommended)
- **TrOCR (Hugging Face)**: Transformer-based OCR for clean documents
- **Configurable**: Easy to add new OCR providers

### LLM Providers
- **Ollama**: Local LLM inference (Mistral, Llama, CodeLlama)
- **OpenAI**: GPT models via API
- **Extensible**: Plugin architecture for additional providers

### Production Features
- **Docker Deployment**: Complete containerized setup
- **Health Monitoring**: Real-time health checks for all services
- **Error Handling**: Robust error handling and logging
- **API Documentation**: Auto-generated OpenAPI/Swagger docs
- **File Upload**: Multi-part form support for direct file processing

## ğŸ“‹ Requirements

- Python 3.11+
- Docker & Docker Compose
- Ollama (for local LLM inference)
- 4GB+ RAM recommended

## ğŸ›  Installation

### 1. Clone the Repository
```bash
git clone https://github.com/yourusername/promptflow.git
cd promptflow
```

### 2. Environment Setup
```bash
# Copy environment template
cp .env.example .env

# Edit configuration as needed
nano config.yaml
```

### 3. Docker Deployment (Recommended)
```bash
# Start all services
docker-compose up -d

# Check service status
docker-compose ps

# View logs
docker-compose logs -f app
```

### 4. Local Development Setup
```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Install Ollama (for LLM support)
# Visit: https://ollama.ai/download

# Pull required models
ollama pull mistral
ollama pull llama3.2

# Start the application
uvicorn main:app --reload
```

## ğŸ¯ Quick Start

### 1. Check System Health
```bash
curl http://localhost:8000/health
```

### 2. View Available Flows
```bash
curl http://localhost:8000/catalog
```

### 3. OCR + LLM Analysis
```bash
# Upload and analyze an image/document
curl -X POST http://localhost:8000/api/v1/ocr_analysis/upload \
  -F "file=@your-document.jpg" \
  -F "analysis_type=comprehensive" \
  -F "ocr_provider=tesseract" \
  -F "languages=en"
```

### 4. Document Text Extraction (Core)
```bash
# Extract text from a PDF document
curl -X POST http://localhost:8000/api/v1/document-extraction/extract \
  -F "file=@document.pdf" \
  -F "chunk_text=true"
```

### 5. Document Analysis Flow (Complete Workflow)
```bash
# Extract and analyze document with LLM
curl -X POST http://localhost:8000/api/v1/document-analysis/analyze-document \
  -F "file=@contract.docx" \
  -F "analysis_prompt=Analyze this contract and identify key terms" \
  -F "chunk_text=true"
```

### 6. Check Flow Information
```bash
# Document analysis flow info
curl http://localhost:8000/api/v1/document-analysis/info

# Core document extraction info
curl http://localhost:8000/api/v1/document-extraction/info
```

## ğŸ“– API Documentation

Once the application is running, visit:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **OpenAPI JSON**: http://localhost:8000/openapi.json

## ğŸ”§ Configuration

### OCR Configuration (`config.yaml`)
```yaml
ocr:
  default_provider: "tesseract"
  providers:
    tesseract:
      tesseract_config: "--oem 3 --psm 6"
      supported_formats: [".jpg", ".jpeg", ".png", ".tiff", ".bmp"]
    huggingface:
      model_name: "microsoft/trocr-base-printed"
      device: "cpu"
      use_gpu: false
```

### LLM Configuration
```yaml
llm:
  default_provider: "ollama"
  default_model: "mistral"
  providers:
    ollama:
      base_url: "http://localhost:11434"
      available_models: ["mistral", "llama3.2", "codellama"]
```

### Environment Variables
```bash
# .env file
OPENAI_API_KEY=your_openai_api_key_here
OLLAMA_BASE_URL=http://localhost:11434
LOG_LEVEL=INFO
MAX_FILE_SIZE=10485760  # 10MB
```

## ğŸ— Architecture

### Flow-Based Processing
```
Input â†’ OCR Provider â†’ Text Extraction â†’ LLM Analysis â†’ Structured Output
```

### Available Flows
1. **OCR Analysis Flow**: Complete OCR + LLM document analysis
2. **Document Analysis Flow**: Complete document text extraction + LLM analysis
3. **Sample Flow**: Basic demonstration flow

### Project Structure
```
promptflow/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ api/                 # API endpoints
â”‚   â”œâ”€â”€ core/               # Core business logic
â”‚   â”œâ”€â”€ flows/              # Processing flows
â”‚   â”œâ”€â”€ providers/          # OCR and LLM providers
â”‚   â””â”€â”€ utils/              # Utility functions
â”œâ”€â”€ flows/
â”‚   â”œâ”€â”€ ocr_analysis/       # OCR + LLM analysis flow
â”‚   â”œâ”€â”€ document_analysis/  # Document extraction + LLM analysis flow
â”‚   â””â”€â”€ sample_flow/        # Sample demonstration flow
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ document_extraction/ # Core document extraction providers
â”‚   â”œâ”€â”€ llm/                # LLM providers and managers
â”‚   â”œâ”€â”€ ocr/                # OCR providers and managers
â”‚   â””â”€â”€ ...                 # Other core components
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml         # Configuration file
â”œâ”€â”€ docker/
â”‚   â””â”€â”€ Dockerfile          # Docker configuration
â”œâ”€â”€ tests/                  # Test suite
â”œâ”€â”€ docs/                   # Documentation
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ docker-compose.yml      # Docker Compose setup
â””â”€â”€ README.md              # This file
```

## ğŸ§ª Testing

### Run Tests
```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=app tests/

# Run specific test file
pytest tests/test_ocr.py -v
```

### Test OCR Providers
```bash
# Test Tesseract
curl http://localhost:8000/api/v1/ocr_analysis/ocr-health?provider=tesseract

# Test TrOCR
curl http://localhost:8000/api/v1/ocr_analysis/ocr-health?provider=huggingface
```

## ğŸ“Š Performance

### OCR Performance Comparison
| Provider | Document OCR | Scene Text | Speed | Languages |
|----------|-------------|------------|-------|-----------|
| Tesseract | â­â­â­â­â­ | â­â­â­â­â­ | ~0.3s | 100+ |
| TrOCR | â­â­â­â­ | â­â­ | ~0.5s | 40+ |

### Benchmarks
- **Average OCR Processing**: 0.3-0.5 seconds per image
- **LLM Analysis**: 1-3 seconds depending on model and complexity
- **Memory Usage**: ~2GB for basic setup, ~4GB with GPU acceleration
- **Concurrent Requests**: Supports up to 10 concurrent requests

## ğŸ” Use Cases

### Document Processing
- **Invoices**: Extract amounts, dates, vendor information
- **Receipts**: Parse transaction details and totals
- **Forms**: Extract structured data from filled forms
- **Contracts**: Identify key terms and parties

### Scene Text Recognition
- **Signage**: Extract text from photographs of signs
- **Screenshots**: Process text from application screenshots
- **Multi-language Documents**: Process documents in various languages

## ğŸš€ Deployment

### Production Deployment
```bash
# Use production compose file
docker-compose -f docker-compose.prod.yml up -d

# Scale services
docker-compose up -d --scale app=3
```

### AWS Deployment
```bash
# Example ECS deployment
aws ecs create-service --cluster promptflow-cluster \
  --service-name promptflow-service \
  --task-definition promptflow:1 \
  --desired-count 2
```

## ğŸ”’ Security

- **Input Validation**: All file uploads are validated for type and size
- **Rate Limiting**: API endpoints are rate-limited to prevent abuse
- **Environment Variables**: Sensitive data stored in environment variables
- **Docker Security**: Non-root user in Docker containers

## ğŸ› Troubleshooting

### Common Issues

**OCR Provider Not Working**
```bash
# Check Tesseract installation
tesseract --version

# Verify Docker container health
docker-compose ps
```

**Ollama Connection Issues**
```bash
# Check Ollama service
curl http://localhost:11434/api/tags

# Restart Ollama
ollama serve
```

**Memory Issues**
```bash
# Monitor memory usage
docker stats

# Adjust Docker memory limits in docker-compose.yml
```

## ğŸ“ˆ Monitoring

### Health Checks
- **Application Health**: `/health`
- **OCR Provider Health**: `/api/v1/ocr_analysis/ocr-health`
- **LLM Provider Health**: `/api/v1/llm/health`

### Logging
```bash
# View application logs
docker-compose logs -f app

# View specific service logs
docker-compose logs -f ollama
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guidelines](CONTRIBUTING.md) for details.

### Development Setup
1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Make your changes and add tests
4. Run the test suite: `pytest`
5. Commit changes: `git commit -m 'Add amazing feature'`
6. Push to branch: `git push origin feature/amazing-feature`
7. Open a Pull Request

### Code Style
- Follow PEP 8 for Python code
- Use type hints where appropriate
- Add docstrings to all functions and classes
- Run `black` and `flake8` before committing

## ğŸ“š Documentation

- [API Documentation](docs/api.md)
- [Configuration Guide](docs/configuration.md)
- [Deployment Guide](docs/deployment.md)
- [Contributing Guidelines](CONTRIBUTING.md)

## ğŸ†˜ Support

- **Issues**: [GitHub Issues](https://github.com/yourusername/promptflow/issues)
- **Discussions**: [GitHub Discussions](https://github.com/yourusername/promptflow/discussions)
- **Email**: support@yourproject.com

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- [Tesseract OCR](https://github.com/tesseract-ocr/tesseract) for excellent OCR capabilities
- [Ollama](https://ollama.ai/) for local LLM inference
- [FastAPI](https://fastapi.tiangolo.com/) for the web framework
- [Hugging Face](https://huggingface.co/) for transformer models

## ğŸ“Š Project Stats

![GitHub stars](https://img.shields.io/github/stars/yourusername/promptflow?style=social)
![GitHub forks](https://img.shields.io/github/forks/yourusername/promptflow?style=social)
![GitHub issues](https://img.shields.io/github/issues/yourusername/promptflow)
![GitHub pull requests](https://img.shields.io/github/issues-pr/yourusername/promptflow)

---

**Built with â¤ï¸ for intelligent document processing**

*Last updated: July 2025*
