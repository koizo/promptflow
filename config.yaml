# AI Inference Platform Configuration

# API Configuration
api_prefix: "/api/v1"

# Enabled flows (empty list means all flows are enabled)
enabled_flows: []
  # - sample_flow
  # - ocr_analysis

# Flow execution settings
execution:
  max_concurrent_flows: 10
  default_timeout: 300  # 5 minutes
  
# File upload settings
uploads:
  max_file_size: "50MB"
  allowed_extensions:
    - pdf
    - png
    - jpg
    - jpeg
    - tiff
    - bmp
    - wav
    - mp3
    - txt

# LLM Configuration
llm:
  default_provider: "ollama"
  default_model: "mistral"
  providers:
    ollama:
      base_url: "http://localhost:11434"
      timeout: 60
      available_models:
        - mistral
        - llama3.2
        - llama3.1
        - codellama

# OCR Configuration
ocr:
  default_provider: "huggingface"
  default_model: "microsoft/trocr-base-printed"
  providers:
    huggingface:
      model_name: "microsoft/trocr-base-printed"
      device: "cpu"
      use_gpu: false
      supported_formats: [".jpg", ".jpeg", ".png", ".pdf", ".tiff", ".bmp"]
      max_image_size: "10MB"
      available_models:
        - "microsoft/trocr-base-printed"
        - "microsoft/trocr-large-printed"
        - "microsoft/trocr-base-handwritten"
        - "microsoft/trocr-large-handwritten"
    tesseract:
      tesseract_cmd: null  # Use system default
      tesseract_config: "--oem 3 --psm 6"
      supported_formats: [".jpg", ".jpeg", ".png", ".tiff", ".bmp"]
      max_image_size: "10MB"

# Logging configuration
logging:
  level: INFO
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
