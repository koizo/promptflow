# Redis Flow State Management Integration Plan
# AI Inference Platform - Executor-Based Architecture
# Created: July 10, 2025

## üéØ OVERVIEW
Integrate Redis StateStore with the executor-based flow engine for persistent 
flow and step management, enabling resumption, recovery, and distributed execution.

Current Status: Redis infrastructure ready, StateStore implemented, needs integration

## üìã IMPLEMENTATION PHASES

### PHASE 1: Core Integration Foundation ‚úÖ
Status: ‚úÖ COMPLETED (July 10, 2025)
Priority: High
Test Results: üéâ ALL TESTS PASSED

#### 1.1 Update FlowRunner with StateStore Integration ‚úÖ
File: core/flow_engine/flow_runner.py
- [x] Add StateStore initialization to FlowRunner.__init__()
- [x] Add async initialize() method for Redis connection
- [x] Import StateStore and FlowState schemas
- [x] Add error handling for Redis connection failures
- [x] Add graceful fallback to memory-only mode
- [x] Add proper cleanup in stop() method

Implementation Notes:
- Redis connection tested successfully with ping()
- Graceful degradation when Redis unavailable
- Proper error handling and logging implemented

#### 1.2 Enhance FlowContext with Persistence ‚úÖ
File: core/executors/base_executor.py
- [x] Add flow_id parameter to FlowContext.__init__()
- [x] Add redis_enabled flag for optional persistence
- [x] Generate UUID for flow_id if not provided
- [x] Update all FlowContext usage across executors
- [x] Add persist_steps flag for step-level control

Implementation Notes:
- Auto-generates UUID flow_id when not provided
- Maintains backward compatibility
- Enhanced logging with flow_id tracking

#### 1.3 Create FlowState Schema Extensions ‚úÖ
File: core/schema.py
- [x] Create FlowStepState model for individual step tracking
- [x] Extend existing FlowState model with step details
- [x] Add status enums (FlowStatus, StepStatus)
- [x] Add timing and metadata fields
- [x] Add helper methods for step management
- [x] Maintain backward compatibility with legacy fields

Implementation Notes:
- Comprehensive step-level state tracking
- Helper methods: get_step_state(), update_step_state(), get_completed_steps()
- Full backward compatibility maintained
- Rich metadata support for analytics

### PHASE 2: Step-by-Step State Persistence ‚è≥
Status: Not Started
Priority: High
Dependencies: Phase 1 complete

#### 2.1 Pre-Step State Saving
File: core/flow_engine/flow_runner.py
- [ ] Add _save_step_state() method
- [ ] Implement pre-step state persistence
- [ ] Add step execution timing
- [ ] Handle step failure state saving

Code Changes:
```python
async def execute_step(self, step: FlowStep, context: FlowContext) -> ExecutionResult:
    # Save step start state
    await self._save_step_state(context.flow_id, step.name, "running", 
                               inputs=step_inputs, started_at=datetime.utcnow())
    
    try:
        result = await executor.execute(context, step_config)
        
        # Save step completion state
        await self._save_step_state(context.flow_id, step.name, "completed",
                                   outputs=result.outputs, completed_at=datetime.utcnow())
        return result
    except Exception as e:
        # Save step failure state
        await self._save_step_state(context.flow_id, step.name, "failed",
                                   error=str(e), completed_at=datetime.utcnow())
        raise
```

#### 2.2 Flow Progress Tracking
File: core/flow_engine/flow_runner.py
- [ ] Add _update_flow_progress() method
- [ ] Track current step and overall status
- [ ] Update flow metadata and timing
- [ ] Handle flow completion state

Code Changes:
```python
async def _update_flow_progress(self, flow_id: str, current_step: str, status: str):
    """Update overall flow progress in Redis"""
    flow_state = await self.state_store.get_flow_state(flow_id)
    if flow_state:
        flow_state.current_step = current_step
        flow_state.status = status
        await self.state_store.save_flow_state(flow_state)
```

### PHASE 3: Flow Resumption & Recovery ‚úÖ
Status: ‚úÖ COMPLETED (July 10, 2025)
Priority: Medium
Dependencies: Phase 2 complete
Test Results: üéâ 100% SUCCESS RATE (13/13 tests passed)

#### 3.1 Flow Resume Capability ‚úÖ
File: core/flow_engine/flow_runner.py
- [x] Add resume_flow() method
- [x] Implement step dependency resolution for resume
- [x] Add _execute_from_step() helper method
- [x] Handle partial flow state reconstruction

Implementation Notes:
- resume_flow() successfully resumes flows from last successful step
- Proper error handling for non-existent flows
- Integration with Redis state management working perfectly

#### 3.2 Failure Recovery ‚úÖ
File: core/flow_engine/flow_runner.py
- [x] Add retry_failed_step() method
- [x] Implement single step retry logic
- [x] Add step reset functionality (_reset_step_state)
- [x] Handle retry limits and backoff

Implementation Notes:
- retry_failed_step() correctly identifies and retries failed steps
- Step state reset functionality working properly
- Proper validation of step existence and failure status

#### 3.3 Flow Cancellation ‚úÖ
File: core/flow_engine/flow_runner.py
- [x] Add cancel_flow() method
- [x] Implement flow cancellation with state persistence
- [x] Handle already completed/cancelled flows
- [x] Update flow state to 'cancelled' in Redis

Implementation Notes:
- cancel_flow() successfully cancels running flows
- State persistence correctly updated in Redis
- Proper handling of edge cases (already completed flows)

#### 3.4 Context Reconstruction ‚úÖ
File: core/flow_engine/flow_runner.py
- [x] Add _reconstruct_execution_context() method
- [x] Rebuild FlowContext from Redis state
- [x] Restore step results as ExecutionResult objects
- [x] Handle completed step outputs properly

Implementation Notes:
- Context reconstruction working perfectly
- ExecutionResult objects properly created from saved outputs
- Step results correctly restored for flow resumption

#### 3.5 Enhanced Error Handling ‚úÖ
File: core/flow_engine/flow_runner.py
- [x] Proper ValueError exceptions for invalid operations
- [x] Graceful handling of non-existent flows/steps
- [x] Redis connection failure handling
- [x] Comprehensive error logging

Implementation Notes:
- All error cases properly handled with appropriate exceptions
- Comprehensive logging for debugging and monitoring
- Graceful degradation when Redis unavailable

### PHASE 4: API Integration ‚è≥
Status: Ready to Implement
Priority: Medium
Dependencies: Phase 3 complete ‚úÖ

#### 4.1 Enhanced Flow Execution Endpoints
File: core/flow_engine/api_generator.py
- [ ] Add dynamic async execution based on YAML async_execution flag
- [ ] Add callback_url parameter support for async flows
- [ ] Implement separate worker per flow for isolation
- [ ] Add simplified status endpoint (no time estimates)

New Behavior:
- Same endpoint (/execute) with different response based on flow config
- Async flows return: {"flow_id": "abc123", "status": "queued", "worker": "celery-worker-ocr-analysis"}
- Sync flows return: {"result": {...}, "execution_time": 2.5}

#### 4.2 Dynamic Queue & Worker Management
File: core/flow_engine/celery_config.py (new)
- [ ] Generate one Celery queue per async flow dynamically
- [ ] Create separate worker per async flow for isolation
- [ ] Use Redis as broker/backend (unified with existing Redis)
- [ ] Auto-generate docker-compose.yml with worker services

Queue Strategy:
- One queue per flow: "ocr_analysis", "document_analysis"
- One worker per flow: "celery-worker-ocr-analysis", "celery-worker-document-analysis"
- Dynamic generation based on flows with execution.mode: "async"

#### 4.3 Enhanced Flow Configuration
File: core/flow_engine/yaml_loader.py
- [ ] Parse enhanced execution configuration from YAML
- [ ] Support execution modes: sync, async, auto
- [ ] Add callback configuration parsing
- [ ] Add per-flow concurrency control

Enhanced YAML Config:
```yaml
config:
  execution:
    mode: "async"              # sync, async, or auto
    timeout: 300               # seconds
    retry_count: 3
    auto_resume: true          # auto-resume failed flows
    max_concurrent: 3          # worker concurrency for this flow
  
  callbacks:
    enabled: true              # allow callback URLs
    max_retries: 3            # callback retry attempts
    retry_delay: 60           # seconds between retries
```

#### 4.4 Simplified Status Endpoint
File: core/flow_engine/api_generator.py
- [ ] Add GET /api/v1/{flow-name}/status/{flow_id}
- [ ] Include progress, execution details, callback info
- [ ] Add available actions (cancel, resume)
- [ ] Remove time estimation complexity

Status Response:
```json
{
  "flow_id": "abc123",
  "status": "running",
  "progress": {
    "percentage": 65,
    "current_step": "analyze_content",
    "completed_steps": ["handle_file", "extract_text"],
    "failed_steps": []
  },
  "execution": {
    "started_at": "2025-07-10T12:00:00Z",
    "queue": "ocr_analysis",
    "worker": "celery-worker-ocr-analysis",
    "retry_count": 0
  },
  "callback": {
    "url": "https://myapp.com/webhook",
    "status": "pending",
    "enabled": true
  },
  "actions": {
    "cancel_url": "/api/v1/ocr-analysis/cancel/abc123",
    "resume_url": null
  }
}
```

#### 4.5 Celery Integration with Redis
File: celery_app.py (new)
- [ ] Configure Celery with Redis broker (DB 0) and result backend (DB 1)
- [ ] Create execute_flow_async task with callback URL support
- [ ] Integrate with Phase 3 resumption capabilities
- [ ] Add automatic retry logic with exponential backoff

Celery Task:
```python
@celery_app.task(bind=True, autoretry_for=(Exception,))
def execute_flow_async(self, flow_name: str, inputs: dict, flow_id: str, callback_url: str = None):
    # Store callback URL in Redis flow state
    # Execute flow with existing Redis state persistence
    # TODO: Future - notify callback URL on completion
```

#### 4.6 Dynamic Infrastructure Management
File: docker_compose_generator.py (new)
- [ ] Generate docker-compose.yml based on async flows
- [ ] Create separate worker service per async flow
- [ ] Add per-flow concurrency configuration
- [ ] Support hot-reload of new flows

Auto-generated docker-compose.yml:
```yaml
services:
  app:
    build: .
    depends_on: [redis]
  redis:
    image: redis:7-alpine
    ports: ["6379:6379"]
  celery-worker-ocr-analysis:
    build: .
    command: celery -A app.celery worker -Q ocr_analysis --concurrency=3
    depends_on: [redis]
  celery-worker-document-analysis:
    build: .
    command: celery -A app.celery worker -Q document_analysis --concurrency=2
    depends_on: [redis]
  celery-flower:
    build: .
    command: celery -A app.celery flower
    ports: ["5555:5555"]
```

### PHASE 4A IMPLEMENTATION PLAN

#### Core Infrastructure Tasks:
- [ ] Create celery_app.py with Redis broker configuration
- [ ] Create celery_config.py for dynamic queue generation
- [ ] Create docker_compose_generator.py for infrastructure management
- [ ] Add Celery dependency to requirements.txt

#### API Enhancement Tasks:
- [ ] Modify api_generator.py to detect async_execution from YAML
- [ ] Add callback_url parameter to execute endpoints
- [ ] Implement enhanced status endpoint
- [ ] Add cancel and resume endpoints for async flows

#### Flow Configuration Tasks:
- [ ] Update yaml_loader.py to parse enhanced execution config
- [ ] Add validation for execution configuration
- [ ] Implement auto-detection logic for execution mode
- [ ] Add per-flow concurrency settings

#### Integration Tasks:
- [ ] Integrate Celery tasks with existing FlowRunner
- [ ] Connect with Phase 3 resumption capabilities
- [ ] Add callback URL storage in Redis flow state
- [ ] Test async execution with existing flows

#### Benefits of Phase 4A:
‚úÖ Same endpoint, smart response based on YAML config
‚úÖ One queue per flow for simplicity
‚úÖ Separate worker per flow for isolation
‚úÖ Redis as unified broker/backend/state store
‚úÖ Dynamic infrastructure based on YAML flows
‚úÖ Future-ready callback URL support
‚úÖ Integration with Phase 3 resumption
‚úÖ No hardcoded queues - pure YAML-driven

#### Testing Strategy:
1. Test sync flows (existing behavior unchanged)
2. Test async flows with new queue/worker system
3. Test callback URL storage and retrieval
4. Test status endpoint with progress information
5. Test integration with Phase 3 resumption
6. Test dynamic docker-compose generation

### PHASE 5: Advanced Features ‚è≥
Status: Not Started
Priority: Low
Dependencies: Phase 4 complete

#### 5.1 Flow Caching
File: core/flow_engine/flow_runner.py
- [ ] Add _check_flow_cache() method
- [ ] Add _cache_flow_result() method
- [ ] Implement input hashing for cache keys
- [ ] Add cache TTL management

#### 5.2 Flow Analytics & Monitoring
File: core/flow_engine/flow_runner.py
- [ ] Add _track_flow_metrics() method
- [ ] Implement execution analytics
- [ ] Add performance monitoring
- [ ] Create metrics dashboard endpoints

### PHASE 6: Configuration & Deployment ‚è≥
Status: Not Started
Priority: Low
Dependencies: Phase 5 complete

#### 6.1 Environment Configuration
File: config.yaml
- [ ] Add enhanced Redis settings
- [ ] Add flow engine configuration
- [ ] Add caching and persistence toggles
- [ ] Add monitoring configuration

#### 6.2 Docker Compose Updates
File: docker-compose.yml
Status: ‚úÖ Already Complete
- [x] Redis service configured
- [x] Persistent storage setup
- [x] Health checks implemented
- [x] Redis Commander UI available

## üìä IMPLEMENTATION TIMELINE

### Week 1: Foundation ‚úÖ COMPLETED
- [x] Phase 1: Core Integration (FlowRunner + StateStore) ‚úÖ
- [x] Update FlowContext with flow_id and persistence flags ‚úÖ
- [x] Extend FlowState schema for step tracking ‚úÖ

### Week 2: State Management ‚è≥ IN PROGRESS
- [ ] Phase 2: Step-by-step persistence
- [ ] Implement pre/post step state saving
- [ ] Add flow progress tracking

### Week 3: Recovery Features
- [ ] Phase 3: Flow resumption and retry logic
- [ ] Implement failure recovery mechanisms
- [ ] Add flow cancellation capabilities

### Week 4: API & Advanced Features
- [ ] Phase 4: Enhanced API endpoints
- [ ] Phase 5: Caching and analytics
- [ ] Phase 6: Configuration and testing

## üéØ BENEFITS OF INTEGRATION

### 1. Reliability
- Flow resumption after failures or restarts
- Step-level recovery for granular error handling
- Persistent state survives application restarts

### 2. Scalability
- Distributed execution across multiple app instances
- Concurrent flow management with proper coordination
- Resource optimization through caching

### 3. Observability
- Real-time flow tracking and monitoring
- Execution analytics and performance metrics
- Debugging capabilities with step-by-step visibility

### 4. User Experience
- Async execution for long-running flows
- Progress tracking with status endpoints
- Flow management through REST APIs

## üöÄ CURRENT STATUS

### ‚úÖ Ready Infrastructure
- Redis server running in Docker
- StateStore class fully implemented
- Redis configuration in place
- Health monitoring active

### üîÑ Integration Points
- FlowRunner needs StateStore integration
- FlowContext needs flow_id support
- API endpoints need async capabilities
- Error handling needs persistence

### üìù Testing Strategy
1. Test with existing flows (document_analysis, ocr_analysis)
2. Verify backward compatibility with synchronous execution
3. Test failure scenarios and recovery
4. Performance testing with concurrent flows

## üìã CHECKLIST FOR EACH PHASE

### Before Starting Each Phase:
- [ ] Review dependencies and prerequisites
- [ ] Create feature branch for phase
- [ ] Update this plan with any changes
- [ ] Identify test cases for the phase

### During Implementation:
- [ ] Update status in this file
- [ ] Document any issues or blockers
- [ ] Test incrementally
- [ ] Update code comments and documentation

### After Completing Each Phase:
- [ ] Mark phase as complete in this file
- [ ] Commit changes with descriptive message
- [ ] Test integration with existing functionality
- [ ] Update README if needed

## üêõ KNOWN ISSUES & CONSIDERATIONS

### Potential Challenges:
1. **Backward Compatibility**: Ensure existing synchronous flows still work
2. **Error Handling**: Redis connection failures should not break flows
3. **Performance**: State persistence should not significantly slow execution
4. **Memory Usage**: Large flow states need efficient serialization
5. **Concurrency**: Multiple instances accessing same flow state

### Mitigation Strategies:
1. **Graceful Degradation**: Fall back to in-memory execution if Redis unavailable
2. **Connection Pooling**: Use Redis connection pool for performance
3. **Selective Persistence**: Allow disabling persistence for simple flows
4. **State Compression**: Compress large state objects before storage
5. **Locking Mechanisms**: Use Redis locks for concurrent access control

## üìö REFERENCES

### Files to Modify:
- core/flow_engine/flow_runner.py (main integration)
- core/executors/base_executor.py (FlowContext updates)
- core/schema.py (FlowState extensions)
- core/flow_engine/api_generator.py (new endpoints)
- config.yaml (configuration updates)

### Files Already Ready:
- core/state_store.py (StateStore implementation)
- docker-compose.yml (Redis infrastructure)
- requirements.txt (Redis dependency)

### Testing Files to Create:
- test_redis_integration.py
- test_flow_resumption.py
- test_concurrent_flows.py

---
Last Updated: July 10, 2025
Next Review: After Phase 1 completion
